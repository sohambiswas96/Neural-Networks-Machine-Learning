import numpy as np
import os,cv2

import glob

from sklearn.utils import shuffle

from sklearn.model_selection import train_test_split

import re

from keras.utils import np_utils

import matplotlib.pyplot as plt
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout


def sorted_aphanumeric(data):
    convert = lambda text: int(text) if text.isdigit() else text.lower()
    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] 
    return sorted(data, key=alphanum_key)

def gen_image(arr):
    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)
    plt.imshow(two_d, interpolation='nearest')
    return plt
  
def unique(list1): 
      
    # insert the list to the set 
    list_set = set(list1) 
    # convert the set to the list 
    unique_list = (list(list_set)) 
    for x in unique_list: 
        print(x)
        
#from sklearn.cross_validation import train_test_split

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

PATH = os.getcwd()
# Define data path
data_path = '/content/drive/My Drive/Colab Notebooks/Character Images'   # inset your path

data_dir_list = sorted_aphanumeric(os.listdir(data_path)) # os.listdir(data_path)


img_rows=128
img_cols=128
num_channel=1
num_epoch=20

# Define the number of classes
num_classes = 34

labels_name={'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'A':10,'B':11,'C':12,'D':13,'E':14,'F':15,'G':16,'H':17,'I':18,'J':19,'K':20,'L':21,'M':22,'N':23,'P':24,'R':25,'S':26,'T':27,'U':28,'V':29,'W':30,'X':31,'Y':32,'Z':33} # O,Q is not there in the list

img_data_list=[]
labels_list = []

for dataset in data_dir_list:
  
    img_list = glob.glob(data_path+'/'+ dataset +'/*.png')
    
    label = labels_name[dataset] # label is generated as the library updated above
    for img in img_list:
        input_img=cv2.imread(img,1 )
        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)
        input_img_resize=cv2.resize(input_img,(28,28))
        img_data_list.append(input_img_resize)
        labels_list.append(label)

#print(unique(labels_list))
img_data = np.array(img_data_list)
img_data = img_data.astype('float32')

labels = np.array(labels_list)

#print(unique(labels))
print(np.unique(labels,return_counts=True))
Y = np_utils.to_categorical(labels, num_classes)


#Shuffle the dataset
x,y = shuffle(img_data,Y, random_state=2)


X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2) # divide data into train and test

#Normalization of the data
X_train = X_train / 255
X_test = X_test / 255

Nv = X_train.shape[0]
Nv_test = X_test.shape[0]

#reshape data to fit model
X_train = X_train.reshape(int(Nv),28,28,1)
X_test = X_test.reshape(int(Nv_test),28,28,1)


model = Sequential()
##################   add model layers described in the assignment   #######################

model.add(Conv2D(32, kernel_size=(5,5), activation='relu'))
model.add(MaxPooling2D(pool_size=(3,3)))
model.add(Dropout(0.35))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.35))
model.add(Dense(34, activation='softmax'))

########################################################################################

# 8. Compile model
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
 
# 9. Fit model on training data
model.fit(X_train, y_train, batch_size=32, nb_epoch=10, verbose=1) #epochs  = iterations(Nit)

# 10. Evaluate model on test data
score = model.evaluate(X_test, y_test, verbose=1)

print('Testing accuracy - > ',score[1] * 100)
 
ytested = model.predict_classes(X_test)
for i in range(10):
  print("The Predicted Testing image is =%s verify below" % ((list(labels_name.keys())[list(labels_name.values()).index(ytested[i])])))
  gen_image(X_test[i]).show() # printing image vs the predicted image below
